{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiverTwilight/Deep_Learning_Full_Example/blob/master/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EzQhFI_imOU"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This is a full example of how to detect hand-writting number with deep learning. The example is based on the MNIST dataset, which contains 60,000 training images and 10,000 testing images. Each image is a 28x28 grayscale image of a hand-written digit. The goal is to train a model to correctly classify the digit in the image.\n",
        "\n",
        "<a href=\"https://ibb.co/zXNKG13\"><img src=\"https://i.ibb.co/3pktBwx/0f63c745a964ec5cd2e85cda9cb656a.jpg\" alt=\"0f63c745a964ec5cd2e85cda9cb656a\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_training = True"
      ],
      "metadata": {
        "id": "RwXl6HSPOKEN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdTZJ42evAVC"
      },
      "source": [
        "## Dataset Process\n",
        "\n",
        "This will transform the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Custome Dataset"
      ],
      "metadata": {
        "id": "6Mc8rwDOo2Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Project/NeuralNetwork/data'\n",
        "\n",
        "def load_custom_data(one_hot_label=False, flatten=False):\n",
        "    img_size = 784\n",
        "\n",
        "    x_train = []\n",
        "    t_train = []\n",
        "\n",
        "    for foldername in os.listdir(data_path):\n",
        "        bundle_path = os.path.join(data_path, foldername)\n",
        "        print(bundle_path)\n",
        "        if os.path.isdir(bundle_path):\n",
        "            for file_name in os.listdir(bundle_path):\n",
        "                img = cv2.imread(os.path.join(bundle_path, file_name))\n",
        "\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                retval, dst = cv2.threshold(gray,170,255,cv2.THRESH_BINARY_INV + cv2.THRESH_TOZERO)\n",
        "\n",
        "                flattened_img = dst.flatten()\n",
        "\n",
        "                flattened_img = flattened_img.astype(np.float32)\n",
        "\n",
        "                img_processed = flattened_img.reshape(dst.shape)\n",
        "                cv2_imshow(img_processed)\n",
        "\n",
        "                label = int(file_name.split('.')[0])\n",
        "\n",
        "                flattened_img /= 255.0\n",
        "\n",
        "                # print(flattened_img)\n",
        "                \n",
        "                x_train.append(flattened_img)\n",
        "\n",
        "                if one_hot_label:\n",
        "                    one_hot = [0] * 10\n",
        "                    one_hot[label] = 1\n",
        "                    t_train.append(one_hot)\n",
        "\n",
        "                else:\n",
        "                    t_train.append(label)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    t_train = np.array(t_train)\n",
        "\n",
        "    # print('x_train shape:', x_train.shape)\n",
        "    # print('t_train shape:', t_train.shape)\n",
        "\n",
        "    return {\n",
        "        \"x\": x_train,\n",
        "        \"t\": t_train\n",
        "    }\n",
        "\n",
        "load_custom_data(one_hot_label=True)"
      ],
      "metadata": {
        "id": "tYhjEh7dZmQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7552deb0-b775-4643-e727-59632bd156ee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52DAE1FBB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAX0lEQVR4nGNgGFjQgi7AhMT+gi7JgmB2c+LR+VQUj5WxGCJIOn/hk2TFI7lUCI/kfX48kl+FMd0IB5iORdaJTxILgAff5Ed4VBViEYMb+xCfJDMeO6u+45FUxOOcwQMAnE8M5AZfFf8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9F40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmElEQVR4nGNgIBLMXoBbrpZhcRFuOQYGhsYm7JJLGRgYGBjmtOOzuG0hPtlYBJMJXa4fic0IpRd8y2KY+I+R5W8+VuPcWzGEEMZGfcXtjoUMSyfgc2caLmOnMjAwyODTyVCHXSfEulf4dKZi1bkAwvmCVfI9hMOOVfIXAwMDA0OhHVZJYQYGBgaGD0nYnVK9gGESzjQyRAAA4XYcVmrzmj8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfklEQVR4nGNgoBhUVeOVnpKHVzoXjc+EzPmJT1IUnyTbUjySaDxU7p9IPJI/8Nn5EU2SBYm99DEDblCHLoBsLHoYIBu74j0eUzHDHclY9MBDBuhRgmznqqcMDAwMK/5GY5M80cfQ95I7AkUnI5QuPqv6yz4Jh40uE/A4Z9AAAB34F5rAEgTXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhklEQVR4nGNgIBcwovFbX/7/zjodq9L2qQwMDAwMgdjkFkPpIHx2+UJpJixyab5YBKFgUi5uuaVYnQMFrggmpp08+CS5sQcBFATgk2Tw7ccnG92ETzZhBj5ZbwYGBuzBx8DAwIZPkgGf5F88kl6uWIUZGBgY5nnNxSmXE4fbFXErcMvRAQAAL9ISjXHBAZoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkElEQVR4nGNgwAMYkTmzn38WKccmWfXo/0tB+5xJF1UqMUwonsswqwePDXl45HIxhZjgLBY8GkuxiMF1vsYnKYJHch4XHsk/fHgk/3HgkeT6g0cy7iUeSYZfWCQRIAGvbD9mXCGDSSV4pUNReKhx0fEehcuEzIn624nLyLwodBG4sXX39JNx6JoePgeXgdQHAHYrHgHYV7T0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9FA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGAjQPhGnFCMDA8OKVz+4uDkjsEtCwJwf375wVOGzY/oCfLIZyBwmVLkeKzwak1F4LCi8+Z/waMxB5aLa+QePZBk+58Sg8ZF1LpXEozEXXQBZ52d8kip4TG3BEEHS+R6f5F98kmp4rKQfAAAaCBPWERY5rQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9F40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nGNgGDSgnYGBgYGBCatcowQejZl45GqgNFZjv0FpFixyE7nxmJoBY2Az9ieMgcXYhY/wmFoCZ2Ex9iU+ST44C9PORY8YGBa+lI3EqvOh4uxilrK7DVgl3/1+0xvNUKPah03yzz9lBgYGhuiv2CS5kiA0DzbJbwxheLwCBd+xSX6A0iLYdEzqYGBgYGAow25eZQMDA0MxAwMDAyM26WYWAXypCAIA3jofi7oCoLEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAr0lEQVR4nH2QrQ7CQBCEPyiS8KN4Kp4BTAkCgUOgSEggNRAMgiZUNrwPmgRJMFiaNBigvdvbPTV7c99k9sA4DXm1iQYj7fkC0q3uQZYD0PTNCGB8C5svADpKbgxwCJOcpkCpmPSBhxILK7RVgOHuK+QPZddir4MkP9GS3rkwwOVfBVZ5WmbPSF1XUpL3Soq2SdtIndS0Tx7fBjivD16hS9cAY2fyyNIAZ+7okLlX9QNSJxu+hmNWgAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9FA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAm0lEQVR4nGNgGARgJRKbiYGBgWEuksgJdNUVCGYZsjgTAwMDAxuC/wLTohIYY2ILsjALAwMDA8NHGPfCfCxujIHSQVjkGBgiIVQSVkmGtMkMDAwzW1HEmGCMWRxFsxku8DMwMDD0wsQYkVV2bjcT+c1Wit1ohlBULhMKjxdVkgWZM/8xHp2flfFIvonGI/mJAY/kP3yS0gyDHAAAgpUYf5gw8koAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/.ipynb_checkpoints\n",
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9FA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAW0lEQVR4nGNgoAuYjk/SxA+Jw4QmafMAjyT7PzyS39nwSP6UwCP5QxKP5As1PJKfJBhwAzNkDrpOVnySongke/nxSL7QxuOeRBQemk5GsiW/4JGc8wePewY7AACZ2Q1+3jmAHQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E90D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlElEQVR4nGNgGORgATKHCU1yIx7JTE88pvqi8NB0sjIwLJ+DQ7LTiIHh/Hs4lwVF8uwqBoavajh0yjIwMPzlxO6cWgYGBoY0HA56xcDAwPBjIkNPFaadBY8Xvf727fTHlBcKmJK3pa8Lyv89gxJIaMAHh50MDAwMDJx4JFcI4JF8KoRH8hUPHskbrzDdCAfVeOToAQCvxR/nj6/D4QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGCwgq5iBgYGBgQVDou/j89eH0xkYGBgYGNHlZj6XS2Jw3I/b1NpECM2ETfKiCx73eDPg1jlHCo/kfRU8pqbAGNh0fsQnKQpjYIYQQ9c/YqzEZuxfPJIrpPFIXlHGYyVSuGLqtMzCo3MwAwDJYhNfqGbfQwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9FA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhUlEQVR4nGNgGAUMjAwMDK0X+RkY/12JycGtzGcBbrmF3njMd8YixgSlk72wSLJAqErGYpxmTk7AKszEwMDAMG0yC1ZJRgYGBgaG6Y8//3gpOROnyQwM9TF4JBlCsdoJBf/wSE6Sw2NqFIYIQmdsAIYk3IMJymE4zUzpwCnVZrkIj2OwAwBRMxX1Q72qPwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAbElEQVR4nGNgGI5geiG6CBOCyfYGXZIRwQx8YyLw/z/zT6ZmmAgLXG7O7IRMBoZFHz8wY7PTFUMEyc6/2XjsZGBoeMkqWovNUCjoCKrAI8vg1IwpVjYTQk9C0omwc/mtn8z/mIXz8Zk6CtAAAO21F2ltjEYKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAW0lEQVR4nGNgoAlgROPP/80djUOy8rga0+Mfe/EYVu2HzypHGIMJi6QAHsk8ZzymRuORi8QjF4/ERrczwA2JgxoINVtYtH7+Y2Jg+PzWphdN29zomXgsHAV0AwC/SREPnOFx8gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkElEQVR4nGNgGKmgD49cuzWCzYguGfnc8vNL9iXYdUYzMDAwlIYzMDAwMDChS4ovZmBg6GbGLtl3noGBIdoCuyQD9yoGhud5uNxbwBC5GJccA4N8JpSBaSxDrwQPTsm2cyeV+nGY2RbLwMCQiUNSl4GBgWF+G3ZjhSYyMDCc4WdgYMAStgwdX9lYK3AYO9AAAE+VF1eKpM/yAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E90D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvUlEQVR4nGNgoBQsmrSSgYEhBlWQBUJlvChjYGBgeIAqycTAwMDAUCJSxsDAwJBuic3QIAjluBSbTmkI52M0FsnFEhCLBRmwSMYyMzAwMDCcNMEmyfCOgYGBIYtdHk0S4pX3DAwMk97pZWHVyczAMO1mw0d0T0B0zkgTfzSV4R+6JBJYkYIuwoRgPlHDo7MEQwRJ51d8koxkS0phSLLAWTNYMCQROt9ieBNJEiPwkCU/4ZO8himJAPPxSZIKAGB8H66T1bDmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8ED6040>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkklEQVR4nGNgGFnAHZsgE4SaKIJH8rATHlP9sYpCdCY64tEYjl2YiYGBgaHVCI/GJBziTAwMDAyMOCRZGBgY5rzEo/OpKh6d78OW7/nzOjoaq4I8BgYGhkUW2I1lZmBgYIhzmohVkgXC4sUqybWKgYGB4ToO35YwMDBgcw4jAwMDQ66E8HEvHOHLwLB4Pi4Z3AAAulkU0GMGghQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgklEQVR4nGNgGGSAEVNo9s53TNwbcai3TWVgSGZgYGBgYMKUtJvNwKCMS/IbAwODTAkOSS4GBoa4dwwMDAwsmO5hZWBgYJDCrvNBAgMDQ6Mkdp1vGRgYGC6sx65TYiEDwwQRBuw6RS4xMGw4wMDAgDWEAoUexcViCkPBFJwyo4AUAADaFRM9Sn+Q5AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQUlEQVR4nGNgGAXIYEUeuggTgnlOF4/OYAwRJJ3C+CTlMCRZ4KwedjxWZmEKIYz9iU/yMx7J6u94rGSYik9yeAMAW8oHlgzDLDEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeklEQVR4nGNgGAW0B22YQkxw1i2ckpUMDP9wSZYYMjCwYUqyMDAwMDSzhzEwfJh35b9yDoZkm3w0w7Rt/5/0oetkZGDoFYlvuSt9aRM2LxTY5uUxMDBkYJFiYZAIyWdgYGD4g00jFHQ245GMwSYIC6F3+CQ/4TGV2gAAsOoYN9xsTaMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYUlEQVR4nGNgGAXDHyROZ2BgYGBgwSJV9F1jHk59uQwMTivwmOvEwMDAwMCEXfIrHsmZ3HhMdWPArdMsHEIzYko1b/yv9OWL1EpMSad3jEauEQwMDFWCpRjaZszE4xQUAADsahBq6XSM7AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdUlEQVR4nGNgIBcwYhMsesc9lYGBgYEJi1yS+gKzIHwmhi/FI+mLy1gGBgYGFjwaExlw63TiZ2BgwOaV+Wfu/ZL+JDgfq66lzQwMDAy5wXgsZfDpx+1aBuE7eCTvmOE21SWOAZtrM2U+//r0yLoen4NGAcUAAEQAFSS2kiCoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjElEQVR4nGNgGAU4QSUDAwMDC3a5ai0GBgYGJuySX6NxG1oMobDrZMfjmgwG3DpXmOLR2A5jYNE5nQPGYsSUTHjwVVFDOxyroXMYGBgYVhhgN/Y7AwMDQ4QKVo3LGRgYGBjssDvoJgMDA4P9IeySTxgYGGwOQtgYscI46enJzCNYbWRgYKiejEuGBAAAwq4UbsmlnjIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAt0lEQVR4nN2QoQ8BcRTHP9zNTLCRJN3/oduuCBpBOdtNu3KnCecfwK7oikqVRIIZmmmSzWyC8HPC7/euCl55b9/Pe9v3++BvKvOd2oVnrZ+yFcXQSEEADF2JBao1NdkG4AGAWxRhDsA7LzSYBeAGhDudJVG86mG7NqyoS/KTU2WWAluv/XJ+7BkUoB4DZhJsYGB1gCSQBq9jAPy7BMtqXG0kQxYAjiP6IZyC3zX1zxOCS2kkH/663hNBIql3V0hxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdElEQVR4nGNgGEqAEUNkwvdjwQkQJgua1KxbBQxBr7GaMztlGgMDgzmMi6xz5hX2OQwMDAVcJ3E7ww/OYsKQq/TGrY8hFMHE0Flih0djNB65amQOurHvkTloITSBFY+pWSg8NGOf45GceRePqQxT8UkOcgAAYOQTJ939spkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F530A5E9AC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhklEQVR4nGNgGLogexIKlwWF90ucgWHSLeFGrJJPtid9viOMKgYHptNwWzm7Fp970PiMSOyF03X4mPlrsOrzUalnYGCYbItNrt4wloGBgYEhsRePxUg6mdDlZrPh07gIq/A8BgYGhpJUJBEkYxnnMjAUvZ6NJInszwKpC0otOO3rwOOWwQ8AiUIYWk5eB3UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 't': array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use MINIST dataset"
      ],
      "metadata": {
        "id": "Mx0UVnxyo3tX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Na81Nc7bvCN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d8735a-efda-4708-ab78-bf06921df59c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import sys, os\n",
        "sys.path.append('/content/')\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# dataset_dir = os.path.dirname(os.path.abspath(\"/content\"))\n",
        "dataset_dir = \"/content\"\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"读入MNIST数据集\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 将图像的像素值正规化为0.0~1.0\n",
        "    one_hot_label : \n",
        "        one_hot_label为True的情况下，标签作为one-hot数组返回\n",
        "        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组\n",
        "    flatten : 是否将图像展开为一维数组\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (训练图像, 训练标签), (测试图像, 测试标签)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjRQLf1HjZZY"
      },
      "source": [
        "# Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Funtions"
      ],
      "metadata": {
        "id": "f4IRMbnVNRwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnVM4bfSjk0t",
        "outputId": "3f9d05d1-5a6c-4dfd-ed90-3ea21ca9547a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0]\n",
            "[11  9]\n",
            "[13  8]\n"
          ]
        }
      ],
      "source": [
        "# Activation Function\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def step(x):\n",
        "    y = x > 0\n",
        "    return y.astype(int)\n",
        "\n",
        "print(step(np.array([1, 3, 0])))\n",
        "\n",
        "# Old and widely-used activation function.\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# There are three common places of these three activation function:\n",
        "#\n",
        "#  1. The output is between 0 to 1\n",
        "#  2. Both is liner function\n",
        "#  3. The more important the input is, the bigger the output is.\n",
        "\n",
        "x = np.array([1, 2])\n",
        "w = np.array([[3, 4], [5, 2]]) # The row number should equal to x's length.\n",
        "\n",
        "# Diffrent operation order will output diffrenet result\n",
        "print(np.dot(w, x)) # [11, 9]\n",
        "print(np.dot(x, w)) # [13, 8] [1 x 3 + 2 x 5, 1 x 4 + 2 x 4]\n",
        "\n",
        "# Central Difference Derivation\n",
        "# We use 2 h to reduce the deviation.\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4\n",
        "    return (f(x + h) - f(x - h)) / (2 * h)\n",
        "\n",
        "def func_1(x):\n",
        "    return 0.01 * x ** 2 + 0.1 * x\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = numerical_diff(func_1, x) # This is a valid operation (boardcast)\n",
        "\n",
        "try:\n",
        "    is_training\n",
        "except:\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a - c) # e ^ (a - c)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "def softmax_batch(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 溢出对策\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428IuPKjnPPa"
      },
      "source": [
        "## Cross Entropy Error\n",
        "\n",
        "We want the loss function result as small as possible.\n",
        "\n",
        "We introduce loss function to find a params that generate small loss function result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "wEBMqCA-nRWg"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))\n",
        "    \n",
        "def cross_entropy_error_batch(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    \n",
        "    # Only output the index of the right anwser.\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1) # 1 is the max\n",
        "    \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lnw14Dwl-hc"
      },
      "source": [
        "# Graident\n",
        "\n",
        "In vector calculus, the gradient of a scalar-valued differentiable function \n",
        "$ f $ of several variables is the vector field (or vector-valued function) f whose value at a point is the \"direction and rate of fastest increase\".\n",
        "\n",
        "The most basic way to find the gradient is to use the numerical differentiation method.\n",
        "\n",
        "$$  grad(x, y) = \\frac{f(x + h) - f(x - h)}{2h} $$\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 还原值\n",
        "        it.iternext()   \n",
        "\n",
        "def test_function(x):\n",
        "    return x[0] ** 2 + x[1] ** 2\n",
        "\n",
        "def gradient_desent(f, init_x, lr=0.01, step_num=100):\n",
        "    \"\"\"\n",
        "    lr is Learning Rate. This should not be too large or too small.\n",
        "    \"\"\"\n",
        "\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "\n",
        "    return x\n",
        "```\n",
        "\n",
        "There are four mainstream gradient desend algorithum."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD (Stochastic Gradient Descent)\n",
        "\n",
        "We can get new weights by:\n",
        "\n",
        "$$ W \\leftarrow W - \\eta \\frac{\\delta L}{\\delta W} $$\n",
        "\n",
        "$ \\eta $ is the learning rate, and $ \\frac{\\delta L}{\\delta W} $ is the gradinent of $ W $\n",
        "\n",
        "The SGD sucks when the function is not anisotropic.\n"
      ],
      "metadata": {
        "id": "a6gWqIjrNrdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        for key, val in params.items():\n",
        "            params[key] -= self.lr * grads[key]"
      ],
      "metadata": {
        "id": "fXadNma1P0XQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Momentum\n",
        "\n",
        "This method can make the gradient reach the extreme position faster"
      ],
      "metadata": {
        "id": "PmwLtamENzTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "            params[key] += self.v[key]\n"
      ],
      "metadata": {
        "id": "cSR-RnRXN2j_"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad\n",
        "\n",
        "The AdaGrad (Adaptive Gradient) introduces the **learning rate decay** method. Compared with the momentum method, this method will gradually reduce the learning rate.\n",
        "\n",
        "$$\\Delta w_t = - \\frac{\\eta}{\\sqrt{\\sum_{i=1}^{t} g_{i}^2 + \\epsilon}} g_t$$\n",
        "\n"
      ],
      "metadata": {
        "id": "EvmXJIvTQFwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, learning_rate=0.01, epsilon=1e-8):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.cache = {}\n",
        "\n",
        "    def update(self, params, gradients):\n",
        "        if not self.cache:\n",
        "            for key, value in params.items():\n",
        "                self.cache[key] = np.zeros_like(value)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.cache[key] += gradients[key] * gradients[key]\n",
        "            params[key] -= (self.learning_rate * gradients[key] / (np.sqrt(self.cache[key]) + self.epsilon))\n",
        "\n",
        "        return params\n"
      ],
      "metadata": {
        "id": "zL6TPk60QiFL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "5sOU-gn9YqEA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81T5whX0YrnH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZJkBsNk8NQ"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O3UbAWBlY5f"
      },
      "source": [
        "## Relu\n",
        "\n",
        "Return x if x is larger than 0, otherwise return 0.\n",
        "\n",
        "$$\n",
        "Relu(x) = \\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        1 & \\mbox{if } \\ x > 0 \\\\\n",
        "        0 & \\mbox{otherwise }\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "EWaHBc_BlFmK"
      },
      "outputs": [],
      "source": [
        "class Relu:\n",
        "    def __init__(self) -> None:\n",
        "        self.mask = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x should be a numpy array here\n",
        "        \"\"\"\n",
        "        self.mask = (x <= 0) # An array represting wheather each element is larger than 0. [True, False, False]\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        \"\"\"\n",
        "        Set all the `Ture` in mask to 0\n",
        "        \"\"\"\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sas1Bu3nlPqI"
      },
      "source": [
        "## Affine\n",
        "\n",
        "$$\n",
        "Affine(x) = X • W + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "3_yAy2vhlR8T"
      },
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b) -> None:\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        dot = np.dot(self.x, self.W)\n",
        "        out = dot + self.b # Boardcasting...\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcMMpfamwXf"
      },
      "source": [
        "## SoftmaxWithLoss\n",
        "\n",
        "The Softmax Loss is a widely used loss function in the field of deep learning. It is also referred to as the Cross-entropy loss with softmax.\n",
        "\n",
        "Let us consider the training data, denoted as 't', which is assumed to have undergone one-shot training, represented as follows:\n",
        "\n",
        " $$ t = (0, 0, 0, ..., 1, 0) $$\n",
        "\n",
        "Here, $ t_{k} $ corresponds to the correct answer. The predicted result, denoted by $ z $, can be expressed as:\n",
        "\n",
        " $$ z = (z_{1}, z_{2}, ..., z_{C}) $$\n",
        "\n",
        "The corresponding loss function, 'lz', can be formulated as:\n",
        "\n",
        " $$ l_{z} = \\sum_{i=1}^{C} t_{i} log(z) = -log(z_{k})$$\n",
        "\n",
        "In comparison to a linear function, the logarithmic function better represents our desired objective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "3tKcHjDbmyIJ"
      },
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self, print_result=False) -> None:\n",
        "        self.loss = None\n",
        "        self.print_result = print_result\n",
        "        self.y = None\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t \n",
        "        # Teaching Data. Marking the right answer.\n",
        "        # Set right anwser to 1 and wrongs to 0. For exmaple, [0, 0, 0, 1, 0, 0]\n",
        "\n",
        "        self.y = softmax_batch(x)\n",
        "        self.loss = cross_entropy_error_batch(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization\n"
      ],
      "metadata": {
        "id": "JuVQCcg1HWvr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9qF09xwHaU8"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution "
      ],
      "metadata": {
        "id": "F104OfzFpsmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution:\n",
        "    def __init__(self, W):\n",
        "        self.W = W"
      ],
      "metadata": {
        "id": "CIvPQLzHpuSo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling"
      ],
      "metadata": {
        "id": "G-0ClQiqp3JO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBySGUTJjy39"
      },
      "source": [
        "# Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVl0mOKYmKFr"
      },
      "source": [
        "## Two Layer Net\n",
        "\n",
        "This network reach a accuarcy of 97%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "HUem1Q5Dj09y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01, initParams=None) -> None:\n",
        "        \n",
        "        self.params = {}\n",
        "\n",
        "        if initParams is not None:\n",
        "            self.params = initParams\n",
        "        else:\n",
        "            # Select {hidden_size} numbers from 0 - 0.01 * input_size\n",
        "            self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "            self.params[\"b1\"] = np.zeros(hidden_size)\n",
        "            self.params[\"W2\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "            self.params[\"b2\"] = np.zeros(output_size)\n",
        "\n",
        "        self.layers = OrderedDict() # Remember the order of the addition\n",
        "        self.layers['Affine1'] = Affine(self.params[\"W1\"], self.params[\"b1\"])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params[\"W2\"], self.params[\"b2\"])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss(print_result = (not initParams == None))\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return self.lastLayer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        \n",
        "        # Get the index of the maximum value. If one-shot is enabled the max value is 1\n",
        "        # For example, [[1, 0, 0], [0,0,1]] will be converted to [0, 2]\n",
        "        if t.ndim != 1: t = np.argmax(t, axis=1)\n",
        "\n",
        "        if x.shape[0] <= 5:\n",
        "            print(\"Expected Anwser: \" + str(t))\n",
        "            print(\"Exact Anwser: \" + str(y))\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "\n",
        "        return accuracy\n",
        "    \n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def gradient(self, x, t):\n",
        "        self.loss(x, t)\n",
        "\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        \n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        grads = {}\n",
        "        grads[\"W1\"] = self.layers[\"Affine1\"].dW\n",
        "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
        "        grads[\"W2\"] = self.layers[\"Affine2\"].dW\n",
        "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ikKQHFmTLT"
      },
      "source": [
        "## CNN\n",
        "\n",
        "Convolutional neural networks is an enhanced version, which offers significant advantages, most notably the preservation of data shape. In previous neural network architectures, it was often necessary to convert two-dimensional arrays to one-dimensional arrays. \n",
        "\n",
        "With CNN, however, original-shaped data can be directly inputted into the network, without the need for additional preprocessing steps. As a result, CNNs outperform other neural network architectures, particularly when processing colored images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGTcZ_vTsQnY"
      },
      "source": [
        "# Training\n",
        "\n",
        "## Two Layer Net\n",
        "\n",
        "Print accuacy after each epoch seeking. Randomly select 100 images to update the gradient.\n",
        "\n",
        "It's unusual for the accuracy to plateau after only a few epochs, especially if you're using a relatively large dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training Config\n",
        "\n",
        "network_type = \"TwoLayer\" #@param [\"TwoLayer\", \"CNN\"]\n",
        "learning_rate = 0.1 #@param {type:\"number\"}\n",
        "batch_size =100 #@param {type:\"number\"}\n",
        "iters_num = 10000 #@param {type:\"number\"}\n",
        "optimizer_type = \"Momentum\" #@param [\"SGD\", \"Momentum\", \"AdaGrad\", \"Adam\"]\n",
        "load_params = False #@param {type:\"boolean\"}\n",
        "use_minitest = False #@param {type:\"boolean\"}\n",
        "test_data_source = \"Custom\" #@param [\"MINIST\", \"Custom\"]"
      ],
      "metadata": {
        "id": "b58Yf86LP0q4",
        "cellView": "form"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "pHkHWIfEssBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a414ad24-5fc3-45af-d5cb-ab07705b4766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAX0lEQVR4nGNgGFjQgi7AhMT+gi7JgmB2c+LR+VQUj5WxGCJIOn/hk2TFI7lUCI/kfX48kl+FMd0IB5iORdaJTxILgAff5Ed4VBViEYMb+xCfJDMeO6u+45FUxOOcwQMAnE8M5AZfFf8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmElEQVR4nGNgIBLMXoBbrpZhcRFuOQYGhsYm7JJLGRgYGBjmtOOzuG0hPtlYBJMJXa4fic0IpRd8y2KY+I+R5W8+VuPcWzGEEMZGfcXtjoUMSyfgc2caLmOnMjAwyODTyVCHXSfEulf4dKZi1bkAwvmCVfI9hMOOVfIXAwMDA0OhHVZJYQYGBgaGD0nYnVK9gGESzjQyRAAA4XYcVmrzmj8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfklEQVR4nGNgoBhUVeOVnpKHVzoXjc+EzPmJT1IUnyTbUjySaDxU7p9IPJI/8Nn5EU2SBYm99DEDblCHLoBsLHoYIBu74j0eUzHDHclY9MBDBuhRgmznqqcMDAwMK/5GY5M80cfQ95I7AkUnI5QuPqv6yz4Jh40uE/A4Z9AAAB34F5rAEgTXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhklEQVR4nGNgIBcwovFbX/7/zjodq9L2qQwMDAwMgdjkFkPpIHx2+UJpJixyab5YBKFgUi5uuaVYnQMFrggmpp08+CS5sQcBFATgk2Tw7ccnG92ETzZhBj5ZbwYGBuzBx8DAwIZPkgGf5F88kl6uWIUZGBgY5nnNxSmXE4fbFXErcMvRAQAAL9ISjXHBAZoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkElEQVR4nGNgwAMYkTmzn38WKccmWfXo/0tB+5xJF1UqMUwonsswqwePDXl45HIxhZjgLBY8GkuxiMF1vsYnKYJHch4XHsk/fHgk/3HgkeT6g0cy7iUeSYZfWCQRIAGvbD9mXCGDSSV4pUNReKhx0fEehcuEzIn624nLyLwodBG4sXX39JNx6JoePgeXgdQHAHYrHgHYV7T0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGAjQPhGnFCMDA8OKVz+4uDkjsEtCwJwf375wVOGzY/oCfLIZyBwmVLkeKzwak1F4LCi8+Z/waMxB5aLa+QePZBk+58Sg8ZF1LpXEozEXXQBZ52d8kip4TG3BEEHS+R6f5F98kmp4rKQfAAAaCBPWERY5rQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nGNgGDSgnYGBgYGBCatcowQejZl45GqgNFZjv0FpFixyE7nxmJoBY2Az9ieMgcXYhY/wmFoCZ2Ex9iU+ST44C9PORY8YGBa+lI3EqvOh4uxilrK7DVgl3/1+0xvNUKPah03yzz9lBgYGhuiv2CS5kiA0DzbJbwxheLwCBd+xSX6A0iLYdEzqYGBgYGAow25eZQMDA0MxAwMDAyM26WYWAXypCAIA3jofi7oCoLEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0B20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAr0lEQVR4nH2QrQ7CQBCEPyiS8KN4Kp4BTAkCgUOgSEggNRAMgiZUNrwPmgRJMFiaNBigvdvbPTV7c99k9sA4DXm1iQYj7fkC0q3uQZYD0PTNCGB8C5svADpKbgxwCJOcpkCpmPSBhxILK7RVgOHuK+QPZddir4MkP9GS3rkwwOVfBVZ5WmbPSF1XUpL3Soq2SdtIndS0Tx7fBjivD16hS9cAY2fyyNIAZ+7okLlX9QNSJxu+hmNWgAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAm0lEQVR4nGNgGARgJRKbiYGBgWEuksgJdNUVCGYZsjgTAwMDAxuC/wLTohIYY2ILsjALAwMDA8NHGPfCfCxujIHSQVjkGBgiIVQSVkmGtMkMDAwzW1HEmGCMWRxFsxku8DMwMDD0wsQYkVV2bjcT+c1Wit1ohlBULhMKjxdVkgWZM/8xHp2flfFIvonGI/mJAY/kP3yS0gyDHAAAgpUYf5gw8koAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/.ipynb_checkpoints\n",
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0F10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAW0lEQVR4nGNgoAuYjk/SxA+Jw4QmafMAjyT7PzyS39nwSP6UwCP5QxKP5As1PJKfJBhwAzNkDrpOVnySongke/nxSL7QxuOeRBQemk5GsiW/4JGc8wePewY7AACZ2Q1+3jmAHQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlElEQVR4nGNgGORgATKHCU1yIx7JTE88pvqi8NB0sjIwLJ+DQ7LTiIHh/Hs4lwVF8uwqBoavajh0yjIwMPzlxO6cWgYGBoY0HA56xcDAwPBjIkNPFaadBY8Xvf727fTHlBcKmJK3pa8Lyv89gxJIaMAHh50MDAwMDJx4JFcI4JF8KoRH8hUPHskbrzDdCAfVeOToAQCvxR/nj6/D4QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0F10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGCwgq5iBgYGBgQVDou/j89eH0xkYGBgYGNHlZj6XS2Jw3I/b1NpECM2ETfKiCx73eDPg1jlHCo/kfRU8pqbAGNh0fsQnKQpjYIYQQ9c/YqzEZuxfPJIrpPFIXlHGYyVSuGLqtMzCo3MwAwDJYhNfqGbfQwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhUlEQVR4nGNgGAUMjAwMDK0X+RkY/12JycGtzGcBbrmF3njMd8YixgSlk72wSLJAqErGYpxmTk7AKszEwMDAMG0yC1ZJRgYGBgaG6Y8//3gpOROnyQwM9TF4JBlCsdoJBf/wSE6Sw2NqFIYIQmdsAIYk3IMJymE4zUzpwCnVZrkIj2OwAwBRMxX1Q72qPwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0F10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAbElEQVR4nGNgGI5geiG6CBOCyfYGXZIRwQx8YyLw/z/zT6ZmmAgLXG7O7IRMBoZFHz8wY7PTFUMEyc6/2XjsZGBoeMkqWovNUCjoCKrAI8vg1IwpVjYTQk9C0omwc/mtn8z/mIXz8Zk6CtAAAO21F2ltjEYKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAW0lEQVR4nGNgoAlgROPP/80djUOy8rga0+Mfe/EYVu2HzypHGIMJi6QAHsk8ZzymRuORi8QjF4/ERrczwA2JgxoINVtYtH7+Y2Jg+PzWphdN29zomXgsHAV0AwC/SREPnOFx8gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0F10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkElEQVR4nGNgGKmgD49cuzWCzYguGfnc8vNL9iXYdUYzMDAwlIYzMDAwMDChS4ovZmBg6GbGLtl3noGBIdoCuyQD9yoGhud5uNxbwBC5GJccA4N8JpSBaSxDrwQPTsm2cyeV+nGY2RbLwMCQiUNSl4GBgWF+G3ZjhSYyMDCc4WdgYMAStgwdX9lYK3AYO9AAAE+VF1eKpM/yAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvUlEQVR4nGNgoBQsmrSSgYEhBlWQBUJlvChjYGBgeIAqycTAwMDAUCJSxsDAwJBuic3QIAjluBSbTmkI52M0FsnFEhCLBRmwSMYyMzAwMDCcNMEmyfCOgYGBIYtdHk0S4pX3DAwMk97pZWHVyczAMO1mw0d0T0B0zkgTfzSV4R+6JBJYkYIuwoRgPlHDo7MEQwRJ51d8koxkS0phSLLAWTNYMCQROt9ieBNJEiPwkCU/4ZO8himJAPPxSZIKAGB8H66T1bDmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0F10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkklEQVR4nGNgGFnAHZsgE4SaKIJH8rATHlP9sYpCdCY64tEYjl2YiYGBgaHVCI/GJBziTAwMDAyMOCRZGBgY5rzEo/OpKh6d78OW7/nzOjoaq4I8BgYGhkUW2I1lZmBgYIhzmohVkgXC4sUqybWKgYGB4ToO35YwMDBgcw4jAwMDQ66E8HEvHOHLwLB4Pi4Z3AAAulkU0GMGghQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/NeuralNetwork/data/bundle_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgklEQVR4nGNgGGSAEVNo9s53TNwbcai3TWVgSGZgYGBgYMKUtJvNwKCMS/IbAwODTAkOSS4GBoa4dwwMDAwsmO5hZWBgYJDCrvNBAgMDQ6Mkdp1vGRgYGC6sx65TYiEDwwQRBuw6RS4xMGw4wMDAgDWEAoUexcViCkPBFJwyo4AUAADaFRM9Sn+Q5AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQUlEQVR4nGNgGAXIYEUeuggTgnlOF4/OYAwRJJ3C+CTlMCRZ4KwedjxWZmEKIYz9iU/yMx7J6u94rGSYik9yeAMAW8oHlgzDLDEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeklEQVR4nGNgGAW0B22YQkxw1i2ckpUMDP9wSZYYMjCwYUqyMDAwMDSzhzEwfJh35b9yDoZkm3w0w7Rt/5/0oetkZGDoFYlvuSt9aRM2LxTY5uUxMDBkYJFiYZAIyWdgYGD4g00jFHQ245GMwSYIC6F3+CQ/4TGV2gAAsOoYN9xsTaMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYUlEQVR4nGNgGAXDHyROZ2BgYGBgwSJV9F1jHk59uQwMTivwmOvEwMDAwMCEXfIrHsmZ3HhMdWPArdMsHEIzYko1b/yv9OWL1EpMSad3jEauEQwMDFWCpRjaZszE4xQUAADsahBq6XSM7AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdUlEQVR4nGNgIBcwYhMsesc9lYGBgYEJi1yS+gKzIHwmhi/FI+mLy1gGBgYGFjwaExlw63TiZ2BgwOaV+Wfu/ZL+JDgfq66lzQwMDAy5wXgsZfDpx+1aBuE7eCTvmOE21SWOAZtrM2U+//r0yLoen4NGAcUAAEQAFSS2kiCoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjElEQVR4nGNgGAU4QSUDAwMDC3a5ai0GBgYGJuySX6NxG1oMobDrZMfjmgwG3DpXmOLR2A5jYNE5nQPGYsSUTHjwVVFDOxyroXMYGBgYVhhgN/Y7AwMDQ4QKVo3LGRgYGBjssDvoJgMDA4P9IeySTxgYGGwOQtgYscI46enJzCNYbWRgYKiejEuGBAAAwq4UbsmlnjIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAt0lEQVR4nN2QoQ8BcRTHP9zNTLCRJN3/oduuCBpBOdtNu3KnCecfwK7oikqVRIIZmmmSzWyC8HPC7/euCl55b9/Pe9v3++BvKvOd2oVnrZ+yFcXQSEEADF2JBao1NdkG4AGAWxRhDsA7LzSYBeAGhDudJVG86mG7NqyoS/KTU2WWAluv/XJ+7BkUoB4DZhJsYGB1gCSQBq9jAPy7BMtqXG0kQxYAjiP6IZyC3zX1zxOCS2kkH/663hNBIql3V0hxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0C40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdElEQVR4nGNgGEqAEUNkwvdjwQkQJgua1KxbBQxBr7GaMztlGgMDgzmMi6xz5hX2OQwMDAVcJ3E7ww/OYsKQq/TGrY8hFMHE0Flih0djNB65amQOurHvkTloITSBFY+pWSg8NGOf45GceRePqQxT8UkOcgAAYOQTJ939spkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F52D8FC0700>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhklEQVR4nGNgGLogexIKlwWF90ucgWHSLeFGrJJPtid9viOMKgYHptNwWzm7Fp970PiMSOyF03X4mPlrsOrzUalnYGCYbItNrt4wloGBgYEhsRePxUg6mdDlZrPh07gIq/A8BgYGhpJUJBEkYxnnMjAUvZ6NJInszwKpC0otOO3rwOOWwQ8AiUIYWk5eB3UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.60784316 0.627451   0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.49019608 0.         0.6392157  0.44705883 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.49019608 0.         0.\n",
            " 0.         0.         0.5058824  0.50980395 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.64705884 0.         0.         0.         0.\n",
            " 0.         0.6117647  0.5294118  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.5254902  0.6313726  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.3647059\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.56078434 0.3647059  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.627451   0.5882353  0.\n",
            " 0.         0.5686275  0.56078434 0.5647059  0.5803922  0.5686275\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.2784314  0.52156866 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.6313726  0.47843137 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.6313726  0.\n",
            " 0.64705884 0.5647059  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.4\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.58431375\n",
            " 0.         0.         0.         0.50980395 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.49411765 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.5647059  0.         0.         0.         0.         0.\n",
            " 0.40784314 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.39607844 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.627451   0.         0.         0.         0.\n",
            " 0.         0.         0.34901962 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.56078434\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.3764706  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.5372549  0.         0.\n",
            " 0.         0.         0.         0.44313726 0.61960787 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.6117647  0.         0.         0.         0.\n",
            " 0.         0.38039216 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.48235294 0.627451   0.         0.57254905 0.44705883 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.2        0.62352943 0.99215686 0.62352943 0.19607843\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1882353  0.93333334\n",
            " 0.9882353  0.9882353  0.9882353  0.92941177 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.21176471 0.8901961  0.99215686 0.9882353  0.9372549\n",
            " 0.9137255  0.9882353  0.22352941 0.02352941 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.03921569 0.23529412 0.8784314\n",
            " 0.9882353  0.99215686 0.9882353  0.7921569  0.32941177 0.9882353\n",
            " 0.99215686 0.47843137 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.6392157  0.9882353  0.9882353  0.9882353  0.99215686\n",
            " 0.9882353  0.9882353  0.3764706  0.7411765  0.99215686 0.654902\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.2        0.93333334\n",
            " 0.99215686 0.99215686 0.74509805 0.44705883 0.99215686 0.89411765\n",
            " 0.18431373 0.30980393 1.         0.65882355 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.1882353  0.93333334 0.9882353  0.9882353  0.7019608\n",
            " 0.04705882 0.29411766 0.4745098  0.08235294 0.         0.\n",
            " 0.99215686 0.9529412  0.19607843 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14901961 0.64705884\n",
            " 0.99215686 0.9137255  0.8156863  0.32941177 0.         0.\n",
            " 0.         0.         0.         0.         0.99215686 0.9882353\n",
            " 0.64705884 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.02745098 0.69803923 0.9882353  0.9411765  0.2784314\n",
            " 0.07450981 0.10980392 0.         0.         0.         0.\n",
            " 0.         0.         0.99215686 0.9882353  0.7647059  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.22352941\n",
            " 0.9882353  0.9882353  0.24705882 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.99215686 0.9882353  0.7647059  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.7764706  0.99215686 0.74509805\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         1.         0.99215686\n",
            " 0.76862746 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.29803923 0.9647059  0.9882353  0.4392157  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.99215686 0.9882353  0.5803922  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.33333334 0.9882353\n",
            " 0.9019608  0.09803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.02745098 0.5294118\n",
            " 0.99215686 0.7294118  0.04705882 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.33333334 0.9882353  0.8745098  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.02745098 0.5137255  0.9882353  0.88235295 0.2784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.33333334 0.9882353  0.5686275  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1882353  0.64705884\n",
            " 0.9882353  0.6784314  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.3372549  0.99215686\n",
            " 0.88235295 0.         0.         0.         0.         0.\n",
            " 0.         0.44705883 0.93333334 0.99215686 0.63529414 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.33333334 0.9882353  0.9764706  0.57254905\n",
            " 0.1882353  0.11372549 0.33333334 0.69803923 0.88235295 0.99215686\n",
            " 0.8745098  0.654902   0.21960784 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.33333334 0.9882353  0.9882353  0.9882353  0.8980392  0.84313726\n",
            " 0.9882353  0.9882353  0.9882353  0.76862746 0.50980395 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.10980392 0.78039217\n",
            " 0.9882353  0.9882353  0.99215686 0.9882353  0.9882353  0.9137255\n",
            " 0.5686275  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.09803922 0.5019608  0.9882353\n",
            " 0.99215686 0.9882353  0.5529412  0.14509805 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "minist_dataset = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "if test_data_source == \"Custom\":\n",
        "    custom_dataset = load_custom_data(one_hot_label=True)\n",
        "    print(custom_dataset['x'])\n",
        "    (x_train, t_train), (x_test, t_test) = minist_dataset[0], (custom_dataset['x'], custom_dataset['t'])\n",
        "else:\n",
        "    (x_train, t_train), (x_test, t_test) = minist_dataset\n",
        "\n",
        "print(x_test[1])\n",
        "print(x_train[1])\n",
        "\n",
        "def train(x_train, t_train, x_test, t_test, initParams=None):\n",
        "    network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10, initParams=initParams)\n",
        "\n",
        "    optimizer = None\n",
        "\n",
        "    if optimizer_type == \"SGD\":\n",
        "        optimizer = SGD()\n",
        "    elif optimizer_type == \"Momentum\":\n",
        "        optimizer = Momentum()\n",
        "    elif optimizer_type == \"AdaGard\":\n",
        "        optimizer = SGD()\n",
        "    else:\n",
        "        optimizer = SGD()\n",
        "\n",
        "    train_size = x_train.shape[0] # 60000\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "    for i in range(iters_num):\n",
        "        batch_mask = np.random.choice(train_size, batch_size) # Select a batch_size between 0 - train_size\n",
        "        \n",
        "        # Randomly select a part of data\n",
        "        x_batch = x_train[batch_mask]\n",
        "        t_batch = t_train[batch_mask]\n",
        "\n",
        "        if not initParams:\n",
        "            grads = network.gradient(x_batch, t_batch)\n",
        "            optimizer.update(network.params, grads)\n",
        "\n",
        "        loss = network.loss(x_batch, t_batch)\n",
        "        train_loss_list.append(loss)\n",
        "\n",
        "        # Only calcuate accuracy every epoch. All data passed in.\n",
        "        if i % iter_per_epoch == 0:\n",
        "            train_acc = network.accuracy(x_train, t_train)\n",
        "            test_acc = network.accuracy(x_test, t_test)\n",
        "            train_acc_list.append(train_acc)\n",
        "            test_acc_list.append(test_acc)\n",
        "            # print(train_acc, test_acc)\n",
        "\n",
        "    epochs = range(len(train_acc_list))\n",
        "    plt.plot(epochs, train_acc_list, label='Train Accuracy')\n",
        "    plt.plot(epochs, test_acc_list, label='Test Accuracy')\n",
        "    plt.title('Accuracy Change Per Epoch' + \" (with Param Cache)\" if load_params else \"\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return network.params\n",
        "\n",
        "dataset_dir = \"/content\"\n",
        "save_file = dataset_dir + \"/params.pkl\"\n",
        "dataset = None\n",
        "\n",
        "if os.path.exists(save_file) and load_params:\n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "\n",
        "batch_mask = np.random.choice(10000, 5) \n",
        "# test_data = np.array(x_test[batch_mask])\n",
        "# expected_answer = np.array(t_test[batch_mask])\n",
        "\n",
        "params = train(x_train, t_train, x_test, t_test, dataset)\n",
        "\n",
        "if not load_params:\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(params, f, -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "1. Saito Yasuhiro. Deep Learning from Scratch[M]. Japan: O'Reilly Japan, 2016.\n",
        "\n",
        "2. 管他叫大靖. (2021年05月24日). Softmax Loss 的推导及改进. 知乎专栏. (https://zhuanlan.zhihu.com/p/374018199).\n",
        "\n",
        "3. Khelifi Ahmed Aziz. Medium. Learn How to Write Markdown & LaTeX in The Jupyter Notebook (https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd)"
      ],
      "metadata": {
        "id": "GFggngb-Zdlh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RjRQLf1HjZZY",
        "428IuPKjnPPa",
        "vnZJkBsNk8NQ",
        "gBySGUTJjy39",
        "lVl0mOKYmKFr",
        "V4ikKQHFmTLT"
      ],
      "provenance": [],
      "mount_file_id": "18B-Fujnr7uDhfyERZzWHTI3-31anw5OH",
      "authorship_tag": "ABX9TyN4pWyK384D3mTvmqTpfxr8",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}